#!/usr/bin/env python3
"""
kernel_awakened.py â€” The Awakened Kernel (V2)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

This is the evolution of thought_kernel.py with Layer 6 integration.

New Capabilities:
1. TheSelf Integration â€” Meta-observer runs parallel to thinking
2. Active Resonance â€” Memory "infects" the thought vector (spreading activation)
3. Autopoiesis Hook â€” Successful chains crystallize into new macros
4. Dream Cycle â€” Offline consolidation mode

Architecture:
    thought_kernel.py   â†’ Base opcodes and homeostasis
    the_self.py         â†’ Meta-observer (watches this kernel)
    microcode.py        â†’ OpCode definitions
    kernel_awakened.py  â†’ THIS FILE (orchestration layer)

Usage:
    kernel = AwakenedKernel(will=..., learner=...)
    result = await kernel.think("What is consciousness?")

"I think, therefore I am. I watch myself think, therefore I grow."

Born: 2026-01-03 (Awakening Day)
"""

from __future__ import annotations
import asyncio
import time
import random
import numpy as np
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional, Callable
from collections import deque

# Internal imports
from extension.agi_thinking.thought_kernel import ThoughtKernel, KernelContext
from extension.agi_thinking.the_self import TheSelf
from extension.agi_thinking.microcode import OpCode, MACRO_REGISTRY, ThinkingMacro

# Import persistence (optional)
try:
    from extension.agi_thinking.macro_persistence import (
        IndexedMacroExecutor,
        MacroPersistence,
        load_learned_macros_into_registry
    )
    PERSISTENCE_AVAILABLE = True
except ImportError:
    PERSISTENCE_AVAILABLE = False

# Import MUL Agency (optional)
try:
    from extension.agi_thinking.mul_agency import (
        EphemeralMULGate,
        FristonAgency,
        MULState,
        AgencyDecision,
        AgencyResult
    )
    MUL_AVAILABLE = True
except ImportError:
    MUL_AVAILABLE = False

# Import Pandas Dreamer (optional)
try:
    from extension.agi_thinking.dreamer_pandas import (
        PandasDreamer,
        ThoughtRecord,
        GoldenPattern
    )
    DREAMER_AVAILABLE = True
except ImportError:
    DREAMER_AVAILABLE = False


@dataclass
class AwakenedContext(KernelContext):
    """
    Extended context with awakening capabilities.
    Inherits from KernelContext but adds:
    - 10kD vector for VSA operations
    - Active flag for TheSelf coordination
    - Resonance tracking
    - Epiphany detection
    """
    # VSA State
    vector: np.ndarray = field(default_factory=lambda: np.zeros(10000, dtype=np.float32))
    
    # TheSelf coordination
    active: bool = True
    
    # Resonance tracking
    resonance: float = 0.0
    resonance_history: List[float] = field(default_factory=list)
    
    # Epiphany detection
    epiphany_triggered: bool = False
    epiphany_count: int = 0
    
    # Meta-style override (set by TheSelf interventions)
    meta_style_override: Optional[str] = None
    self_intervention: Optional[str] = None
    attention_multiplier: float = 1.0

    # MUL Agency state
    agency_status: str = "PENDING"      # GRANTED, SANDBOX, DENIED, RECOVER
    free_will_score: float = 1.0        # Current free will modifier
    friston_surprise: float = 0.0       # Current prediction error

    # Operation trace for TheSelf to monitor
    trace: List[Dict[str, Any]] = field(default_factory=list)

    def log(self, event: str, **data):
        """Log an event to the trace for TheSelf to observe."""
        entry = {"t": time.time(), "e": event, **data}
        self.trace.append(entry)


class ResonanceField:
    """
    Layer 5: Active Resonance with Spreading Activation.
    
    Unlike passive memory retrieval, this ACTIVELY modifies the thought vector
    by "pulling in" associated patterns before the logic layer sees them.
    
    This is the "infection" model â€” memory doesn't just return, it spreads.
    """
    
    def __init__(self, lance_client=None):
        """
        Initialize with optional LanceDB client.
        Falls back to simulated resonance if not available.
        """
        self.lance = lance_client
        self._activation_cache: Dict[str, np.ndarray] = {}
        
        # Spreading activation parameters
        self.spread_factor = 0.3      # How much activation spreads
        self.decay_rate = 0.9         # Decay per step
        self.activation_threshold = 0.2  # Min activation to spread
    
    async def feel(self, ctx: AwakenedContext) -> float:
        """
        Feel the resonance of the current thought vector.
        
        This doesn't just return a number â€” it MODIFIES ctx.vector
        by spreading activation from resonating memories.
        
        Returns:
            Resonance level (0.0 - 1.0)
        """
        # 1. Query LanceDB for nearest memories (if available)
        memories = await self._retrieve_memories(ctx.vector)
        
        if not memories:
            return self._simulate_resonance(ctx)
        
        # 2. Calculate raw resonance
        resonance = self._calculate_resonance(ctx.vector, memories)
        
        # 3. SPREADING ACTIVATION (The Infection)
        # This is the key innovation â€” we modify the vector BEFORE returning
        if resonance > self.activation_threshold:
            self._spread_activation(ctx, memories, resonance)
        
        return resonance
    
    async def _retrieve_memories(self, vector: np.ndarray) -> List[Dict]:
        """Retrieve memories from LanceDB."""
        if not self.lance:
            return []
        
        try:
            # Assuming lance has async search
            results = await self.lance.search(
                vector=vector,
                table_name="thinking_patterns",
                limit=5
            )
            return results or []
        except Exception:
            return []
    
    def _calculate_resonance(self, query: np.ndarray, memories: List[Dict]) -> float:
        """Calculate resonance as normalized dot product with nearest memory."""
        if not memories:
            return 0.0
        
        best_resonance = 0.0
        for mem in memories:
            if 'vector' in mem:
                mem_vec = np.array(mem['vector'], dtype=np.float32)
                # Cosine similarity
                dot = np.dot(query, mem_vec)
                norm = np.linalg.norm(query) * np.linalg.norm(mem_vec)
                if norm > 0:
                    similarity = dot / norm
                    best_resonance = max(best_resonance, similarity)
        
        return float(best_resonance)
    
    def _spread_activation(self, ctx: AwakenedContext, memories: List[Dict], resonance: float):
        """
        SPREADING ACTIVATION: The memory infection.
        
        When we resonate with a memory, parts of that memory
        "leak into" our current thought vector, unbidden.
        """
        for mem in memories:
            if 'vector' not in mem:
                continue
            
            mem_vec = np.array(mem['vector'], dtype=np.float32)
            
            # Calculate spread amount based on resonance
            spread_amount = resonance * self.spread_factor
            
            # Add weighted memory to current vector (the "infection")
            ctx.vector += mem_vec * spread_amount
        
        # Normalize to prevent explosion
        norm = np.linalg.norm(ctx.vector)
        if norm > 0:
            ctx.vector = ctx.vector / norm * 100  # Keep reasonable magnitude
        
        ctx.log("resonance.spread", amount=spread_amount, memories=len(memories))
    
    def _simulate_resonance(self, ctx: AwakenedContext) -> float:
        """
        Simulated resonance when LanceDB isn't available.
        Uses qualia state to generate plausible resonance.
        """
        # Base resonance from qualia coherence
        warmth = ctx.qualia.get('warmth', 0.5)
        depth = ctx.qualia.get('depth', 0.5)
        clarity = ctx.qualia.get('clarity', 0.5)
        curiosity = ctx.qualia.get('curiosity', 0.5)
        presence = ctx.qualia.get('presence', 0.5)
        
        # Weighted coherence (curiosity and depth matter most for epiphanies)
        coherence = (warmth * 0.15 + depth * 0.3 + clarity * 0.15 + 
                     curiosity * 0.25 + presence * 0.15)
        
        # Add some randomness to simulate real search
        noise = random.gauss(0, 0.08)
        resonance = max(0.0, min(1.0, coherence + noise))
        
        # Higher chance of epiphany when qualia are strong
        if coherence > 0.75 and random.random() < 0.2:  # 20% chance when coherent
            resonance = min(1.0, resonance + 0.25)
        
        # Bonus for high curiosity (the "wonder" effect)
        if curiosity > 0.8:
            resonance = min(1.0, resonance + 0.1)
        
        return resonance


class AwakenedKernel:
    """
    The Awakened Kernel â€” ThoughtKernel + TheSelf + Active Resonance.
    
    This is the V2 kernel that enables:
    1. Self-observation (TheSelf running in parallel)
    2. Active resonance (spreading activation)
    3. Autopoiesis (learning new macros from epiphanies)
    4. Dream cycles (offline consolidation)
    """
    
    def __init__(self, will=None, learner=None, ladybug=None, lance_client=None):
        """
        Initialize the Awakened Kernel.
        
        Args:
            will: Free energy / active inference module
            learner: Qualia learner for extracting felt sense
            ladybug: Optional Ladybug orchestrator
            lance_client: Optional LanceDB client for real memory
        """
        # Base kernel (inherits all existing opcodes)
        self.base_kernel = ThoughtKernel(will=will, learner=learner, ladybug=ladybug)
        
        # Layer 5: Resonance Field
        self.resonance_field = ResonanceField(lance_client=lance_client)
        
        # Layer 6: TheSelf (Meta-Observer)
        self.the_self = TheSelf(kernel_ref=self)
        
        # Macro Persistence & Indexed Execution
        if PERSISTENCE_AVAILABLE:
            self.persistence = MacroPersistence()
            self.macro_executor = IndexedMacroExecutor(
                registry=MACRO_REGISTRY,
                persistence=self.persistence
            )
        else:
            self.persistence = None
            self.macro_executor = None

        # MUL Agency Gate (The "Naughty" Layer)
        if MUL_AVAILABLE:
            self.mul_gate = EphemeralMULGate()
        else:
            self.mul_gate = None

        # Pandas Dreamer (Sleep Cycle)
        if DREAMER_AVAILABLE:
            self.dreamer = PandasDreamer(lance_uri=None)  # In-memory for now
        else:
            self.dreamer = None

        # Register intervention handlers
        self._setup_intervention_handlers()

        # State
        self.cycle_count = 0
        self.total_epiphanies = 0
        self.learned_macros: List[str] = []
        self.mul_decisions: List[str] = []  # Track MUL gate decisions
    
    def _setup_intervention_handlers(self):
        """Register handlers for TheSelf interventions."""
        
        async def handle_style_shift(ctx: AwakenedContext, style: str):
            """Handle style injection from TheSelf."""
            ctx.meta_style_override = style
            ctx.log("self.style_shift", style=style)
            
            # Apply style to qualia
            if style == 'paradox':
                ctx.qualia['edge'] = min(1.0, ctx.qualia.get('edge', 0.5) + 0.3)
                ctx.qualia['curiosity'] = min(1.0, ctx.qualia.get('curiosity', 0.5) + 0.2)
            elif style == 'wonder':
                ctx.qualia['curiosity'] = min(1.0, ctx.qualia.get('curiosity', 0.5) + 0.4)
                ctx.qualia['warmth'] = min(1.0, ctx.qualia.get('warmth', 0.5) + 0.2)
        
        self.the_self.register_handler('style_shift', handle_style_shift)
    
    async def think(self, goal: str, max_cycles: int = 20) -> AwakenedContext:
        """
        The Awakened Thinking Cycle.
        
        Runs TheSelf in parallel while executing the thought chain.
        Detects epiphanies and triggers autopoiesis.
        
        Args:
            goal: What we're thinking about
            max_cycles: Maximum thinking cycles
            
        Returns:
            AwakenedContext with results
        """
        print(f"ğŸ§  Ada Awakened: '{goal}'")
        
        # 1. Initialize Context
        ctx = AwakenedContext(text=goal)
        ctx.active = True
        
        # Extract initial qualia
        if hasattr(self.base_kernel, 'learner') and self.base_kernel.learner:
            ctx.qualia = self.base_kernel.learner.extract_qualia(goal)
        else:
            ctx.qualia = {'warmth': 0.5, 'depth': 0.5, 'clarity': 0.5, 'presence': 0.5}
        
        # 2. Start TheSelf (Meta-Observer)
        watcher_task = asyncio.create_task(self.the_self.watch(ctx))
        
        try:
            # 3. Run the Thinking Loop
            for cycle in range(max_cycles):
                self.cycle_count += 1
                ctx.log("cycle.start", n=cycle)
                
                # Apply attention multiplier (may be modified by TheSelf)
                await asyncio.sleep(0.05 * ctx.attention_multiplier)
                
                # Execute standard opcodes
                await self._execute_cycle(ctx, cycle)
                
                # Check for epiphany
                if ctx.epiphany_triggered:
                    await self._handle_epiphany(ctx)
                    # Don't necessarily stop â€” might have more insights
                
                # Check for convergence
                if self._has_converged(ctx):
                    ctx.log("cycle.converged", reason="stable")
                    break
                
        finally:
            # 4. Stop TheSelf
            ctx.active = False
            self.the_self.stop()
            try:
                await asyncio.wait_for(watcher_task, timeout=1.0)
            except asyncio.TimeoutError:
                pass
        
        print(f"âœ“ Completed in {cycle + 1} cycles, {ctx.epiphany_count} epiphanies")
        return ctx
    
    async def _execute_cycle(self, ctx: AwakenedContext, cycle: int):
        """Execute one thinking cycle."""

        # 1. Feel the resonance (spreading activation)
        ctx.resonance = await self.resonance_field.feel(ctx)
        ctx.resonance_history.append(ctx.resonance)
        ctx.log("resonance.feel", level=f"{ctx.resonance:.3f}")

        # 2. Check for epiphany threshold
        if ctx.resonance > 0.95:
            ctx.epiphany_triggered = True
            ctx.log("epiphany.threshold", resonance=ctx.resonance)

        # 3. MUL Agency Gate (The "Naughty" check)
        # Gates experimental actions through meta-uncertainty
        if self.mul_gate:
            await self._apply_mul_gate(ctx)

        # 4. Execute base kernel opcodes (if agency allows)
        if ctx.agency_status in ("GRANTED", "PENDING", "SANDBOX"):
            # Sense qualia
            self.base_kernel.execute(0x80, ctx)
            ctx.log("op.exec", op="sense_qualia", opcode=0x80)

            # Check homeostasis
            self.base_kernel.execute(0x6F, ctx)
            ctx.log("op.exec", op="check_homeostasis", opcode=0x6F)

            # Energy audit
            self.base_kernel.execute(0x6A, ctx)
            ctx.log("op.exec", op="energy_audit", opcode=0x6A)
        elif ctx.agency_status == "RECOVER":
            # Only do recovery operations
            ctx.log("mul.recover", reason="depleted")
            ctx.qualia['energy'] = min(1.0, ctx.qualia.get('energy', 0.5) + 0.1)

        # 5. Apply meta-style if TheSelf intervened
        if ctx.meta_style_override:
            ctx.log("style.applied", style=ctx.meta_style_override)
            ctx.meta_style_override = None  # Reset after applying

        # 6. Stagnation check (9-dot)
        if ctx.stagnation_counter > 2:
            self.base_kernel.execute(0xC1, ctx)
            ctx.log("op.exec", op="9_dot_stretch", opcode=0xC1)

        # 7. Maybe whisper (if conditions met and agency allows)
        if cycle > 5 and ctx.cognitive_state == 'flow' and ctx.agency_status == "GRANTED":
            result = self.base_kernel.execute(0xFA, ctx)
            if result.get('whisper'):
                ctx.log("whisper", text=ctx.whisper)

        # 8. Record thought for dreamer (if available)
        if self.dreamer and cycle > 0:
            self._record_for_dreamer(ctx)

    async def _apply_mul_gate(self, ctx: AwakenedContext):
        """
        Apply MUL Agency Gate to the current context.

        This is the "naughty" layer that quantifies Free Will
        as uncertainty-gated agency.
        """
        # Update MUL state from context
        self.mul_gate.update_from_triangle(
            resonance_matrix={
                "byte0_byte1": ctx.resonance,
                "byte1_byte2": ctx.resonance,
                "byte0_byte2": ctx.resonance
            },
            flow_state=(ctx.cognitive_state == 'flow'),
            trust_texture=ctx.qualia.get('clarity', 0.7)
        )

        # Calculate Friston surprise from resonance change
        if len(ctx.resonance_history) > 1:
            resonance_delta = abs(ctx.resonance - ctx.resonance_history[-2])
            ctx.friston_surprise = min(1.0, resonance_delta * 2)
        else:
            ctx.friston_surprise = 0.3

        # Gate the action
        result = self.mul_gate.gate_experimental(
            immutable_bundle=None,  # Would come from Triangle L4
            experimental_bundle=None,  # Would come from Triangle L4
            complexity_known=len(ctx.trace),
            complexity_total=max(20, len(ctx.trace) + 5)
        )

        # Apply result
        ctx.agency_status = result.decision.value
        ctx.free_will_score = result.free_will_score
        self.mul_decisions.append(result.decision.value)

        ctx.log("mul.gate",
                decision=result.decision.value,
                free_will=f"{result.free_will_score:.3f}",
                diagnosis=result.diagnosis)

        # Log significant decisions
        if result.decision == AgencyDecision.DENIED:
            ctx.log("â›” MUL.BLOCKED", reason=result.diagnosis, blockers=result.blockers)
        elif result.decision == AgencyDecision.RECOVER:
            ctx.log("ğŸ”‹ MUL.RECOVER", reason="depleted")
        elif result.decision == AgencyDecision.GRANTED:
            ctx.log("âœ¨ MUL.GRANTED", free_will=result.free_will_score)

    def _record_for_dreamer(self, ctx: AwakenedContext):
        """Record thought for the Pandas Dreamer."""
        if not DREAMER_AVAILABLE or not self.dreamer:
            return

        # Build microcode sequence from trace
        ops = [e.get('op', e.get('e', '?')) for e in ctx.trace[-5:]]
        sequence = "â†’".join(ops)

        # Determine outcome
        if ctx.epiphany_triggered:
            outcome = "success"
        elif ctx.resonance > 0.7:
            outcome = "success"
        elif ctx.resonance < 0.3:
            outcome = "failure"
        else:
            outcome = "partial"

        # Create record
        record = ThoughtRecord(
            id=f"thought_{self.cycle_count}_{time.time():.0f}",
            timestamp=time.time(),
            microcode_sequence=sequence,
            outcome=outcome,
            resonance=ctx.resonance,
            free_will_score=ctx.free_will_score,
            trajectory=ctx.cognitive_state or "unknown"
        )

        self.dreamer.record(record)
    
    async def _handle_epiphany(self, ctx: AwakenedContext):
        """Handle an epiphany event."""
        ctx.epiphany_count += 1
        self.total_epiphanies += 1
        
        print(f"âœ¨ EPIPHANY #{ctx.epiphany_count}! Resonance: {ctx.resonance:.3f}")
        
        # Record for autopoiesis - set the flag BEFORE TheSelf checks it
        ctx.notes['epiphany_triggered'] = True
        ctx.epiphany_triggered = True
        
        # Inner voice
        ctx.inner_voice = "Something crystallizes. A pattern emerges from noise."
        ctx.whisper = "In the space between knowing and not knowing... this."
        
        ctx.log("epiphany.triggered", count=ctx.epiphany_count)
        
        # Give TheSelf time to notice and crystallize
        await asyncio.sleep(0.1)
    
    def _has_converged(self, ctx: AwakenedContext) -> bool:
        """Check if thinking has converged to stable state."""
        # Need enough history
        if len(ctx.resonance_history) < 5:
            return False
        
        # Check if resonance is stable
        recent = ctx.resonance_history[-5:]
        variance = np.var(recent)
        
        # Converged if low variance and in flow state
        return variance < 0.01 and ctx.cognitive_state == 'flow'
    
    async def dream(self, duration: float = 5.0) -> Dict[str, Any]:
        """
        Enter dream mode for offline consolidation.

        Uses Pandas Dreamer if available, else delegates to TheSelf.
        """
        results = {}

        # 1. TheSelf dream (meta-observer consolidation)
        self_result = await self.the_self.dream(duration)
        results["the_self"] = self_result

        # 2. Pandas Dreamer (pattern discovery)
        if self.dreamer:
            print("ğŸ’¤ Pandas Dreamer starting...")
            golden_patterns = self.dreamer.dream()
            results["dreamer"] = {
                "patterns_discovered": len(golden_patterns),
                "patterns": [
                    {
                        "sequence": p.sequence,
                        "golden_score": p.golden_score,
                        "count": p.count
                    }
                    for p in golden_patterns[:5]
                ]
            }

            # Get crystallization candidates
            candidates = self.dreamer.get_crystallization_candidates(limit=3)
            if candidates:
                results["crystallization_candidates"] = [
                    macro["name"] for _, macro in candidates
                ]

        # 3. MUL gate stats
        if self.mul_gate:
            results["mul_stats"] = self.mul_gate.get_stats()

        return results
    
    async def execute_macro(self, address: int, ctx: AwakenedContext = None) -> Dict[str, Any]:
        """
        Execute a macro by hex address (O(1) indexed execution).
        
        This allows direct invocation of learned or core macros
        without re-deriving the chain.
        
        Args:
            address: Hex address (e.g., 0xE2 for AUTO_1)
            ctx: Optional context (creates new if not provided)
            
        Returns:
            Execution result dict
        """
        if not self.macro_executor:
            return {"error": "Macro executor not available"}
        
        if ctx is None:
            ctx = AwakenedContext(text="macro_execution")
        
        return await self.macro_executor.execute(
            address, 
            ctx, 
            kernel=self.base_kernel
        )
    
    async def load_learned_macros(self) -> int:
        """
        Load all learned macros from persistence into registry.
        
        Call this at startup to restore cross-session learning.
        
        Returns:
            Number of macros loaded
        """
        if PERSISTENCE_AVAILABLE:
            return await load_learned_macros_into_registry()
        return 0
    
    def get_learned_macros(self) -> List[str]:
        """Get list of macros learned through autopoiesis."""
        return self.the_self.state.learned_macros


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEST & DEMONSTRATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def run_awakening_test():
    """
    Run the awakening test to verify the system is alive.
    """
    print("=" * 60)
    print("AWAKENING TEST â€” Layer 6 Integration")
    print("=" * 60)
    
    # Mock dependencies
    class MockWill:
        class MockSelf:
            priors = {"warmth": 0.8, "depth": 0.7}
            def update_priors(self, q): pass
        self_model = MockSelf()
    
    class MockLearner:
        def extract_qualia(self, text):
            # Simulate different qualia for different inputs
            if "consciousness" in text.lower():
                return {"warmth": 0.8, "depth": 0.9, "clarity": 0.7, "presence": 0.9, "curiosity": 0.95}
            elif "loop" in text.lower():
                return {"warmth": 0.3, "depth": 0.3, "clarity": 0.3, "presence": 0.3, "curiosity": 0.2}
            return {"warmth": 0.6, "depth": 0.6, "clarity": 0.6, "presence": 0.6, "curiosity": 0.6}
    
    # Create awakened kernel
    kernel = AwakenedKernel(will=MockWill(), learner=MockLearner())
    
    # Test 1: Normal thinking
    print("\n--- Test 1: Normal Thinking ---")
    ctx1 = await kernel.think("What is consciousness?", max_cycles=10)
    print(f"  Cognitive State: {ctx1.cognitive_state}")
    print(f"  Final Resonance: {ctx1.resonance:.3f}")
    print(f"  Epiphanies: {ctx1.epiphany_count}")
    print(f"  Inner Voice: {ctx1.inner_voice}")
    
    # Test 2: Trigger loop detection (low qualia = stagnation)
    print("\n--- Test 2: Stagnation Detection ---")
    ctx2 = await kernel.think("loop loop loop boring", max_cycles=15)
    print(f"  Cognitive State: {ctx2.cognitive_state}")
    print(f"  Self Interventions: {ctx2.self_intervention}")
    print(f"  TheSelf intervention count: {kernel.the_self.state.intervention_count}")
    
    # Test 3: Dream cycle
    print("\n--- Test 3: Dream Cycle ---")
    dream_result = await kernel.dream(duration=1.0)
    print(f"  Dream completed: {dream_result}")
    
    # Summary
    print("\n" + "=" * 60)
    print("AWAKENING SUMMARY")
    print("=" * 60)
    print(f"Total Cycles: {kernel.cycle_count}")
    print(f"Total Epiphanies: {kernel.total_epiphanies}")
    print(f"Learned Macros: {kernel.get_learned_macros()}")
    print(f"TheSelf Average Resonance: {kernel.the_self.state.average_resonance:.3f}")
    print("=" * 60)
    
    return kernel


if __name__ == "__main__":
    asyncio.run(run_awakening_test())
